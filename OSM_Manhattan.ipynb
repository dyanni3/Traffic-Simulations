{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = ox.graph_from_place('Manhattan Island, New York City, New York, USA', network_type='drive',simplify=True)\n",
    "colors=ox.plot.get_edge_colors_by_attr(G,'length',cmap='viridis')\n",
    "fig=ox.plot_graph(G,fig_height=15,fig_width=10,bgcolor='black',edge_color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get edge information, plot histogram of number of lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elist=G.edges.values()\n",
    "blah=[e for e in elist]\n",
    "edf=pd.DataFrame(blah)\n",
    "with plt.style.context('dark_background'):\n",
    "    plt.hist(pd.to_numeric(edf.lanes.dropna(),errors='coerce').dropna(),edgecolor='k')\n",
    "plt.ylabel(\"Number of roads\")\n",
    "plt.xlabel(\"Number of lanes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uG=nx.to_undirected(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len([i for i in nx.strongly_connected_components(G)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elist=[edge for edge in uG.edges]\n",
    "pick=np.random.randint(len(elist),size=3000)\n",
    "droplist=[elist[num] for num in pick]\n",
    "uGp=uG.copy()\n",
    "uGp.remove_edges_from(droplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig=ox.plot_graph(uG,fig_height=15,fig_width=10,node_alpha=.1,colors=list(map(custom_cm,q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig[0].savefig('graphics_NY_pdf.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(elist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lanes_blah=[]\n",
    "for b in blah:\n",
    "    try:\n",
    "        if b['lanes']:\n",
    "            lanes_blah.append(b)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(lanes_blah)\n",
    "df2=pd.DataFrame(blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "street_names=(pd.unique(df2.name[np.array([np.shape(df2.name[i])==() for i in range(len(df2.name))])].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.head()\n",
    "#df2[np.array(df2.width.dropna().index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sort(street_names)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df2.dropna(subset=['lanes'])\n",
    "df=df.drop(['ref','junction','access','bridge','geometry','service','tunnel','width','osmid'],axis=1)\n",
    "df2=df2.drop(['ref','junction','access','bridge','geometry','service','tunnel','width','osmid'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,val in enumerate(df.lanes):\n",
    "    if(len(val)>1):\n",
    "        df.set_value(df.index.astype(int)[i],'lanes',val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,val in enumerate(df.maxspeed):\n",
    "    if(type(val)==str):\n",
    "        df.set_value(df.index.astype(int)[i],'maxspeed',float(val.split(' ')[0]))\n",
    "    elif(type(val)==list):\n",
    "        df.set_value(df.index.astype(int)[i],'maxspeed',float(val[0].split(' ')[0]))\n",
    "for i,val in enumerate(df.highway):\n",
    "    if type(val)!=str:\n",
    "        df.set_value(df.index.astype(int)[i],'highway',val[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.oneway=df.oneway.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.lanes=pd.to_numeric(df.lanes)\n",
    "clean_dat=pd.get_dummies(df.drop('name',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtot=clean_dat.drop('lanes',axis=1)\n",
    "ytot=clean_dat['lanes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train,test=tts(clean_dat)\n",
    "Xtrain=train.drop('lanes',axis=1)\n",
    "ytrain=train['lanes']\n",
    "Xtest=test.drop('lanes',axis=1)\n",
    "ytest=test['lanes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import VotingClassifier as VC\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "model=LR(class_weight='balanced',C=.5)\n",
    "model.fit(Xtrain,ytrain)\n",
    "model2=RFC(class_weight='balanced')\n",
    "model2.fit(Xtrain,ytrain)\n",
    "rfr=RFR()\n",
    "rfr.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LRpred=model.predict(Xtest)\n",
    "RFCpred=model2.predict(Xtest)\n",
    "RFRpred=rfr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    #plt.scatter(RFRpred,ytest+np.random.normal(0,.05,len(ytest)),s=.5,c='g')\n",
    "    #plt.plot(np.arange(7),np.arange(7),'r--')\n",
    "    sns.regplot(RFRpred,ytest,scatter_kws={'s':100,'alpha':.2},ci=99,y_jitter=0,x_jitter=0,fit_reg=True)\n",
    "    plt.xlabel('predicted lanes',fontsize=18)\n",
    "    plt.ylabel('actual num lanes',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weighted_pred=np.sum(model2.predict_proba(Xtest)*np.stack([np.arange(1,8) for i in range(383)]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(r2_score(LRpred,ytest))\n",
    "#print(r2_score(weighted_pred,ytest))\n",
    "print(r2_score(RFRpred,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(accuracy_score([round(i) for i in RFRpred],ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jointplotdata=pd.DataFrame({'predicted number of lanes':RFRpred,'actual number of lanes':ytest.values})\n",
    "with plt.style.context('dark_background'):\n",
    "    #with plt.style.context('seaborn-pastel'):\n",
    "    kdefig=sns.jointplot(x=\"predicted number of lanes\",y='actual number of lanes',data=jointplotdata,kind='kde',cmap='bone',color='steelblue')\n",
    "    #hexplot = sns.jointplot(x, y, kind=\"hex\")\n",
    "    #plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)  # shrink fig so cbar is visible\n",
    "    #cax = kdefig.fig.add_axes([.85, .25, .05, .4])  # x, y, width, height\n",
    "    #plt.colorbar(cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topred=df2[df2.lanes.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topred=topred.drop('lanes',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,val in enumerate(topred.maxspeed):\n",
    "    if(type(val)==str):\n",
    "        topred.set_value(topred.index.astype(int)[i],'maxspeed',float(val.split(' ')[0]))\n",
    "    elif(type(val)==list):\n",
    "        topred.set_value(topred.index.astype(int)[i],'maxspeed',float(val[0].split(' ')[0]))\n",
    "for i,val in enumerate(topred.highway):\n",
    "    if type(val)!=str:\n",
    "        topred.set_value(topred.index.astype(int)[i],'highway',val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topred=pd.get_dummies(topred.drop('name',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col_name in [i for i in Xtrain.columns if i not in topred.columns]:\n",
    "    topred[col_name]=0\n",
    "for col_name in [i for i in topred.columns if i not in Xtrain.columns]:\n",
    "    topred=topred.drop(col_name,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_lanes=rfr.predict(topred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j=0\n",
    "for i,val in enumerate(df2.lanes):\n",
    "    try:\n",
    "        if(np.isnan(float(val))):\n",
    "            df2.set_value(df2.index.astype(int)[i],'lanes',predicted_lanes[j])\n",
    "            j+=1\n",
    "    except TypeError:\n",
    "        print(i,j,' didnt work')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_edges_data=df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_edges_data[['lanes','length']];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graphs=ox.nx.connected_component_subgraphs(uG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subgraph_sizes=[ox.nx.number_of_edges(i) for i in list(graphs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G.number_of_edges()\n",
    "#subgraph_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pperc(L,s,l,rho):\n",
    "    n=rho*L\n",
    "    inner=L*s-.5*s**2\n",
    "    inner=2*inner/(L**2)\n",
    "    inner=inner**(l-1)\n",
    "    outer=1-inner\n",
    "    outer=outer**(n**l)\n",
    "    return(1-outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "rho=np.linspace(0,.06,100)\n",
    "plt.plot(rho,pperc(1000,7,2,rho),'r--')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "road_probs=[]\n",
    "for i in range(len(final_edges_data)):\n",
    "    l=final_edges_data[['lanes','length']].iloc[i]['lanes']\n",
    "    L=final_edges_data[['lanes','length']].iloc[i]['length']\n",
    "    if type(L)==list:\n",
    "        L=L[0]\n",
    "    if type(l)==list:\n",
    "        l=l[0]\n",
    "    road_probs.append(pperc(float(L),7,float(l),.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drops=[]\n",
    "for p in road_probs:\n",
    "    if np.random.random()>np.real(p):\n",
    "        drops.append(True)\n",
    "    else:\n",
    "        drops.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elist=[edge for edge in G.edges]\n",
    "droplist=[elist[i] for i in np.where(drops)[0]]\n",
    "uGp=G.copy()\n",
    "uGp.remove_edges_from(droplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.number_connected_components(nx.to_undirected(uGp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uGp=nx.to_undirected(uGp)\n",
    "print(nx.number_connected_components(uGp))\n",
    "print(max([nx.number_of_edges(ob) for ob in nx.connected_component_subgraphs(uGp)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"getting l and L...\")\n",
    "ls=[]\n",
    "Ls=[]\n",
    "\n",
    "for i in range(len(final_edges_data)):\n",
    "    l=final_edges_data[['lanes','length']].iloc[i]['lanes']\n",
    "    L=final_edges_data[['lanes','length']].iloc[i]['length']\n",
    "    if type(L)==list:\n",
    "        L=L[0]\n",
    "    if type(l)==list:\n",
    "        l=l[0]\n",
    "    ls.append(l)\n",
    "    Ls.append(L)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    \n",
    "num_trials=1\n",
    "num_densities=20\n",
    "densities=np.linspace(0,.08,num_densities)\n",
    "num_components=np.zeros((num_densities,num_trials))\n",
    "biggest_comp=np.zeros((num_densities,num_trials))\n",
    "\n",
    "print(\"starting trials...\")\n",
    "\n",
    "for this_density in range(num_densities):\n",
    "    rho=densities[this_density]\n",
    "    road_probs=[]\n",
    "    print(\"Getting road probabilities, %s ...\"%(str(round(rho,3))))\n",
    "    for i in range(9666):\n",
    "        road_probs.append(pperc(float(Ls[i]),7,float(ls[i]),rho))\n",
    "    for this_trial in range(num_trials):\n",
    "        print(\"running density: %s, trial %d\"%(str(round(rho,3)),this_trial))\n",
    "        drops=[]\n",
    "        for p in road_probs:\n",
    "            if np.random.random()<p:\n",
    "                drops.append(True)\n",
    "            else:\n",
    "                drops.append(False)\n",
    "\n",
    "        elist=[edge for edge in G.edges]\n",
    "        droplist=[elist[i] for i in np.where(drops)[0]]\n",
    "        uGp=G.copy()\n",
    "        uGp.remove_edges_from(droplist)\n",
    "        uGp=nx.to_undirected(uGp)\n",
    "        \n",
    "        num_components[this_density,this_trial]=nx.number_connected_components(uGp)\n",
    "        biggest_comp[this_density,this_trial]=max([nx.number_of_edges(ob) for ob in nx.connected_component_subgraphs(uGp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.loglog(biggest_comp,num_components,'bo')\n",
    "plt.ylabel(\"number of connected components\")\n",
    "plt.xlabel(\"size of biggest component\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.errorbar(x=1000*densities,y=np.average(num_components,axis=1),yerr=np.std(num_components,axis=1))\n",
    "    plt.xlabel(\"Number of hacked cars per kilometer per lane\",fontsize=14)\n",
    "    plt.ylabel(\"number of connected components\",fontsize=14)\n",
    "    plt.grid(c='gray',lw=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with plt.style.context('dark_background'):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.errorbar(x=1000*densities,y=np.average(G_size,axis=1)/biggest_comp[0,0],yerr=np.std(G_size,axis=1)/G_size[0,0])\n",
    "    plt.xlabel(\"Number of hacked cars per kilometer per lane\",fontsize=14)\n",
    "    plt.ylabel(r\"$\\frac{size\\,\\, of \\,\\,largest\\,\\, comp}{size\\,\\, of\\,\\, full \\,\\,network}$\",fontsize=14)\n",
    "    plt.grid(c='gray',lw=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trials=1\n",
    "num_densities=3\n",
    "densities=np.linspace(0,.08,num_densities)\n",
    "num_components_fine=np.zeros((num_densities,num_trials))\n",
    "G_size=np.zeros((num_densities,num_trials))\n",
    "SG_size=np.zeros((num_densities,num_trials))\n",
    "q=np.zeros(num_densities)\n",
    "\n",
    "print(\"starting trials...\")\n",
    "\n",
    "for this_density in range(num_densities):\n",
    "    rho=densities[this_density]\n",
    "    road_probs=[]\n",
    "    print(\"Getting road probabilities, %s ...\"%(str(round(rho,3))))\n",
    "    for i in range(9666):\n",
    "        road_probs.append(pperc(float(Ls[i]),14,float(ls[i]),rho))\n",
    "    q[this_density]=np.average(road_probs)\n",
    "    for this_trial in range(num_trials):\n",
    "        #print(\"running density: %s, trial %d\"%(str(round(rho,3)),this_trial))\n",
    "        drops=[]\n",
    "        for p in road_probs:\n",
    "            if np.random.random()<np.real(p):\n",
    "                drops.append(True)\n",
    "            else:\n",
    "                drops.append(False)\n",
    "\n",
    "        elist=[edge for edge in G.edges]\n",
    "        droplist=[elist[i] for i in np.where(drops)[0]]\n",
    "        uGp=G.copy()\n",
    "        uGp.remove_edges_from(droplist)\n",
    "        uGp=nx.to_undirected(uGp)\n",
    "        \n",
    "        num_components_fine[this_density,this_trial]=nx.number_connected_components(uGp)\n",
    "        this_list=[nx.number_of_edges(ob) for ob in nx.connected_component_subgraphs(uGp)]\n",
    "        G_size[this_density,this_trial]=max(this_list)\n",
    "        if len(this_list)>1:\n",
    "            this_list.remove(max(this_list))\n",
    "            SG_size[this_density,this_trial]=max(this_list)\n",
    "        else:\n",
    "            SG_size[this_density,this_trial]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_components_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pperc(1000,7,1.01,.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rho=0.016\n",
    "road_probs=[]\n",
    "print(\"Getting road probabilities, %s ...\"%(str(round(rho,3))))\n",
    "for i in range(9666):\n",
    "    road_probs.append(pperc(float(Ls[i]),14,float(ls[i]),rho))\n",
    "fig=ox.plot_graph(G,edge_color=list(map(custom_cm,road_probs)),fig_height=15,fig_width=8,node_alpha=0,bgcolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig[0].savefig(\"manhattan_hacked_small.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "road_probs=[pperc(float(Ls[i]),7,float(ls[i]),0.005) for i in range(9666)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ecolors=[[] for i in range(len(uGp.edges))]\n",
    "colors=list(map(plt.cm.rainbow,list(np.random.random(10000))))\n",
    "for i,ob in enumerate(nx.connected_component_subgraphs(uGp)):\n",
    "    print(i)\n",
    "    for j,edge in enumerate(uGp.edges):\n",
    "        if edge in ob.edges:\n",
    "            ecolors[j]=colors[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ox.plot_graph(uGp,node_alpha=0,bgcolor='black',edge_color=ecolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat=plt.hist([nx.number_of_edges(ob) for ob in nx.connected_component_subgraphs(uGp)],bins=np.linspace(0,200,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.loglog(dat[1][:-1],dat[0],'bo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp_sizes=[]\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    drops=[]\n",
    "    for p in road_probs:\n",
    "        if np.random.random()<p:\n",
    "            drops.append(True)\n",
    "        else:\n",
    "            drops.append(False)\n",
    "\n",
    "    elist=[edge for edge in G.edges]\n",
    "    droplist=[elist[i] for i in np.where(drops)[0]]\n",
    "    uGp=G.copy()\n",
    "    uGp.remove_edges_from(droplist)\n",
    "    uGp=nx.to_undirected(uGp)\n",
    "\n",
    "    this_list=[nx.number_of_edges(ob) for ob in nx.connected_component_subgraphs(uGp)]\n",
    "    this_list.remove(max(this_list))\n",
    "    comp_sizes.extend(this_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(comp_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat=plt.hist(comp_sizes,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_densities=300\n",
    "densities=1000*np.linspace(0,.08,num_densities)\n",
    "#with plt.style.context('seaborn-poster'):\n",
    "#ax1=plt.plot()\n",
    "plt.figure(figsize=(6,4.5))\n",
    "plt.errorbar(densities,y=np.average(G_size,axis=1),yerr=np.std(G_size,axis=1),color=np.array([120,120,255])/255,alpha=.7)\n",
    "plt.plot(densities,np.average(G_size,axis=1),color=np.array([120,120,255])/255,marker='o',lw=.3,mec=np.array([120,120,255])/255,ms=6,alpha=.5)\n",
    "#ax2=ax1.twinx()\n",
    "plt.plot(densities,np.average(SG_size,axis=1),c='k',marker='v',alpha=.7,mec='k',ms=4,lw=.3)\n",
    "plt.errorbar(densities,y=np.average(SG_size,axis=1),yerr=np.std(SG_size,axis=1),color=midc_blue,alpha=.7)\n",
    "plt.xticks([10*i for i in range(9)])\n",
    "plt.yticks([1000*i for i in range(9)])\n",
    "plt.ylabel(\"cluster size\",fontsize=18)\n",
    "plt.xlabel(r\"$\\rho_H$\",fontsize=18)\n",
    "plt.grid('gray',lw=.1)\n",
    "plt.xlim(0,30)\n",
    "plt.yticks([2000*i for i in range(5)],fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.legend([\"Largest Component\",\"Second Largest Component\"],fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#ax1=plt.plot()\n",
    "fig,ax1=plt.subplots(figsize=(10,8))\n",
    "ax1.errorbar(q,y=np.average(G_size,axis=1),yerr=np.std(G_size,axis=1),color=tuple(startc),alpha=.5)\n",
    "ax1.plot(q,np.average(G_size,axis=1),color=tuple(startc),marker='o',lw=1.8,mec='k',ms=8,alpha=.9)\n",
    "ax2=ax1.twinx()\n",
    "ax2.plot(q,np.average(SG_size,axis=1),c=tuple(endc),marker='o',alpha=.5,mec='k',ms=8,lw=.5)\n",
    "ax2.errorbar(q,y=np.average(SG_size,axis=1),yerr=.3*np.std(SG_size,axis=1),color='coral',alpha=.3)\n",
    "plt.xticks([.1*i for i in range(11)])\n",
    "ax1.set_ylabel(\"cluster size: G\",fontsize=14)\n",
    "ax2.set_ylabel(\"cluster size: SG\",fontsize=14)\n",
    "plt.xlabel(\"q\")\n",
    "plt.grid('gray',lw=.5)\n",
    "ax1.legend(labels=[\"G\"])\n",
    "ax2.legend(labels=[\"SG\"],loc=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(abs(q-.5)<.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "densities[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install python-google-places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from googleplaces import GooglePlaces, types, lang\n",
    "\n",
    "YOUR_API_KEY = 'AIzaSyADg_bOTei5s9nWXGQRfGr87X-P3ovTGPU'\n",
    "\n",
    "google_places = GooglePlaces(YOUR_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_result = google_places.nearby_search(\n",
    "        location='Manhattan', keyword='Coffee')#,\n",
    "        #radius=200000)#, types=[types.TYPE_HEALTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if query_result.has_attributions:\n",
    "    print (query_result.html_attributions)\n",
    "\n",
    "station_names=[]\n",
    "station_locs=[]\n",
    "station_ids=[]\n",
    "ct=0\n",
    "for place in query_result.places:\n",
    "    # Returned places from a query are place summaries.\n",
    "    station_names.append(place.name)\n",
    "    ct+=1\n",
    "    station_locs.append(place.geo_location)\n",
    "    station_ids.append(place.place_id)\n",
    "\n",
    "    # The following method has to make a further API call.\n",
    "    place.get_details()\n",
    "    # Referencing any of the attributes below, prior to making a call to\n",
    "    # get_details() will raise a googleplaces.GooglePlacesAttributeError.\n",
    "    #print (place.details) # A dict matching the JSON response from Google.\n",
    "    #print (place.local_phone_number)\n",
    "    #print (place.international_phone_number)\n",
    "    #print (place.website)\n",
    "    #print (place.url)\n",
    "\n",
    "\n",
    "#ct=0\n",
    "# Are there any additional pages of results?\n",
    "while( query_result.has_next_page_token and ct<200):\n",
    "    ct+=1\n",
    "    query_result_next_page = google_places.nearby_search(\n",
    "            pagetoken=query_result.next_page_token)\n",
    "    print(\"more pages\")\n",
    "    for place in query_result_next_page.places:\n",
    "        station_names.append(place.name)\n",
    "        station_locs.append(place.geo_location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_tuples=[]\n",
    "for p in station_locs:\n",
    "    station_tuples.append((float(p['lat']),float(p['lng'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "police_nodes=[ox.utils.get_nearest_node(G,station_tuples[i]) for i in range(len(station_tuples))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"length of police_nodes: \"+str(len(police_nodes)))\n",
    "ctr=0\n",
    "num_police_in_graph=[]\n",
    "for ob in nx.connected_component_subgraphs(uGp):\n",
    "    ctr=0\n",
    "    for node in police_nodes:\n",
    "        if node in ob.nodes:\n",
    "            ctr+=1\n",
    "    num_police_in_graph.append((len(ob.nodes),ctr))\n",
    "safe_nodes=0; risk_nodes=0;\n",
    "for tup in num_police_in_graph:\n",
    "    if tup[1]==0:\n",
    "        risk_nodes+=tup[0]\n",
    "    else:\n",
    "        safe_nodes+=tup[0]\n",
    "print(\"fraction of nodes w access to hospital: \"+str(round(safe_nodes/(safe_nodes+risk_nodes),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trials=10\n",
    "num_densities=50\n",
    "densities=np.linspace(0,.08,num_densities)\n",
    "frac_access_coffee=np.zeros((num_densities,num_trials))\n",
    "\n",
    "print(\"starting trials...\")\n",
    "\n",
    "for this_density in range(num_densities):\n",
    "    rho=densities[this_density]\n",
    "    road_probs=[]\n",
    "    print(\"Getting road probabilities, %s ...\"%(str(round(rho,3))))\n",
    "    for i in range(9665):\n",
    "        road_probs.append(pperc(float(Ls[i]),14,float(ls[i]),rho))\n",
    "    #q[this_density]=np.average(road_probs)\n",
    "    for this_trial in range(num_trials):\n",
    "        #print(\"running density: %s, trial %d\"%(str(round(rho,3)),this_trial))\n",
    "        drops=[]\n",
    "        for p in road_probs:\n",
    "            if np.random.random()<np.real(p):\n",
    "                drops.append(True)\n",
    "            else:\n",
    "                drops.append(False)\n",
    "\n",
    "        elist=[edge for edge in G.edges]\n",
    "        droplist=[elist[i] for i in np.where(drops)[0]]\n",
    "        uGp=G.copy()\n",
    "        uGp.remove_edges_from(droplist)\n",
    "        uGp=nx.to_undirected(uGp)\n",
    "        \n",
    "        ctr=0\n",
    "        num_police_in_graph=[]\n",
    "        for ob in nx.connected_component_subgraphs(uGp):\n",
    "            ctr=0\n",
    "            for node in police_nodes:\n",
    "                if node in ob.nodes:\n",
    "                    ctr+=1\n",
    "            num_police_in_graph.append((len(ob.nodes),ctr))\n",
    "        safe_nodes=0; risk_nodes=0;\n",
    "        for tup in num_police_in_graph:\n",
    "            if tup[1]==0:\n",
    "                risk_nodes+=tup[0]\n",
    "            else:\n",
    "                safe_nodes+=tup[0]\n",
    "        print(\"fraction of nodes w access to Times Square: \"+str(round(safe_nodes/(safe_nodes+risk_nodes),3)))\n",
    "        print(\"trial num: \"+str(this_trial))\n",
    "        frac_access_coffee[this_density,this_trial]=safe_nodes/(safe_nodes+risk_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"getting l and L...\")\n",
    "ls=[]\n",
    "Ls=[]\n",
    "\n",
    "for i in range(9665):\n",
    "    l=final_edges_data[['lanes','length']].iloc[i]['lanes']\n",
    "    L=final_edges_data[['lanes','length']].iloc[i]['length']\n",
    "    if type(L)==list:\n",
    "        L=L[0]\n",
    "    if type(l)==list:\n",
    "        l=l[0]\n",
    "    ls.append(l)\n",
    "    Ls.append(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "num_densities=50\n",
    "densities=np.linspace(0,.08,num_densities)\n",
    "#ax1=plt.plot()\n",
    "plt.figure(figsize=(9,4.5))\n",
    "plt.semilogy()\n",
    "#plt.errorbar(q,y=np.average(G_size,axis=1),yerr=np.std(G_size,axis=1),color='g',alpha=.5)\n",
    "plt.errorbar(1000*densities,y=np.average(frac_access_hosp,axis=1),yerr=np.std(frac_access_hosp,axis=1),color='white',marker='^',lw=1.8,mec='r',ms=8,alpha=.6,ecolor='pink')\n",
    "plt.errorbar(1000*densities,y=np.average(frac_access_fire,axis=1),yerr=np.std(frac_access_fire,axis=1),color='red',marker='o',lw=1.8,mec='k',ms=8,alpha=.6)\n",
    "plt.errorbar(1000*densities,y=np.average(frac_access_ts,axis=1),yerr=np.std(frac_access_ts,axis=1)/1.5,color='gray',marker='s',lw=1.8,mec='k',ms=8,alpha=.6)\n",
    "plt.errorbar(1000*densities,y=np.average(frac_access_coffee,axis=1),yerr=np.std(frac_access_coffee,axis=1),color='saddlebrown',marker='o',lw=1.8,mec='k',ms=8,alpha=1)\n",
    "#plt.semilogy(1000*densities,frac_access_police,color='cadetblue',marker='o',lw=1.8,mec='k',ms=8,alpha=.6)\n",
    "#plt.semilogy(1000*densities,frac_access_coffee,color='peru',marker='o',lw=1.8,mec='k',ms=8,alpha=.6)\n",
    "#plt.semilogy(1000*densities,frac_access_hindu,color='purple',marker='o',lw=1.8,mec='k',ms=8,alpha=.6)\n",
    "#ax2=ax1.twinx()\n",
    "#plt.plot(q,np.average(SG_size,axis=1),c='coral',marker='o',alpha=.5,mec='k',ms=8)\n",
    "#plt.errorbar(q,y=np.average(SG_size,axis=1),yerr=2*np.std(SG_size,axis=1),color='coral',alpha=.5)\n",
    "#plt.xticks([.1*i for i in range(11)])\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylim(1e-3,1e0)\n",
    "#locs,_=plt.yticks()\n",
    "locs=np.array([1e-4,1e-3,1e-2,1e-1,1e0])\n",
    "labels=[\"100%\",\"10%\",\"1%\",\"0.1%\",\"0.01%\"]\n",
    "labels=reversed(labels)\n",
    "plt.yticks(locs,labels,fontsize=16)\n",
    "plt.ylabel(\"Percent of nodes with access\",fontsize=18)\n",
    "plt.xlabel(r\"$\\rho_H$\",fontsize=18)\n",
    "plt.xlim(0,60)\n",
    "#plt.grid('gray',lw=.4)\n",
    "plt.legend([\"hospital\",\"fire station\",\"Times Square\",\"coffee shop\",\"hindu temple\"],fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(station_x,station_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names=[]\n",
    "for b in blah:\n",
    "    try:\n",
    "        names.append(b['name'])\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'FDR Drive' in names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making heatmap\n",
    "\n",
    "#1 determine which sims need to be run $n_{hacked}=\\frac{N_{cars}*f_{hacked}}{L_{tot}}$\n",
    "\n",
    "$L_{tot}=\\sum_{roads}^{}{n_{lanes}*length\\,\\, (km)}$\n",
    "\n",
    "#2 get q for each simulation -> $q=\\langle road \\_ probs(n_{hacked}) \\rangle$\n",
    "\n",
    "#3 risk level $r=sigmoid(q)$, color $c = plt.cm.custom(r)$\n",
    "\n",
    "#4 make the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1 determining which sims\n",
    "\n",
    "#Ncars in range 10 thousand to 360,000 (max)\n",
    "Ncars=np.linspace(100,360000,100)\n",
    "\n",
    "#fraction hacked in range 0 to 1\n",
    "f_hacked=np.linspace(0,1,100)\n",
    "\n",
    "#get Ltot\n",
    "Ltot=np.sum(np.array([float(l) for l in ls])*np.array(Ls))/1000\n",
    "\n",
    "#densities to simulate\n",
    "densities_matrix=np.outer(f_hacked,Ncars)/(Ltot*1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2 getting q for each simulation\n",
    "\n",
    "q_matrix=np.zeros(densities_matrix.shape)\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        road_probs=[]\n",
    "        if i%10==0 and j%50==0:\n",
    "            print(\"Getting road probabilities, %s ...\"%(str((i,j))))\n",
    "        for k in range(len(Ls)):\n",
    "            road_probs.append(pperc(float(Ls[k]),7,float(ls[k]),densities_matrix[i,j]))\n",
    "        q_matrix[i,j]=np.average(road_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#3 and 4 determine risk level, and make the heat map\n",
    "def sigmoid(q):\n",
    "    return(1/(1+np.exp((-q+.4)/.06)))\n",
    "\n",
    "risk_matrix=sigmoid(q_matrix)\n",
    "\n",
    "f=plt.figure(figsize=(7,7))\n",
    "#plt.imshow(q_matrix,cmap=test_map(reverse=True),interpolation='none')\n",
    "plt.imshow(risk_matrix,cmap=blues_map(reverse=True),interpolation='none')\n",
    "l1,=plt.plot(np.arange(500),20000/np.arange(1,501),c='pink',label='city fragment',linestyle='--',lw=2)\n",
    "l2,=plt.plot(np.arange(500),5000/np.arange(1,501),c=midc,linestyle='--',label='traffic jams',lw=2)\n",
    "plt.ylim(0,1)\n",
    "yticks=[(100*i) for i in range(6)]\n",
    "xticks=yticks\n",
    "plt.yticks(yticks,[round(.2*i,3) for i in range(6)],fontsize=16)\n",
    "plt.xticks(xticks,[72*i for i in range(6)],fontsize=16)\n",
    "plt.ylabel(\"Fraction hacked\",fontsize=18)\n",
    "plt.xlabel(\"Total number of cars (thousands)\",fontsize=18)\n",
    "cb=plt.colorbar(label=\"Probability of Fragmentation\",shrink=.6,orientation='horizontal')\n",
    "cb.set_label(r\"Probability of city fragmentation\",fontsize=12)\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.flipud(densities_matrix))\n",
    "plt.xlabel(\"Ncars\")\n",
    "plt.ylabel(\"f_hacked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(densities_matrix)*1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testim=np.zeros((150,150))\n",
    "for i in range(150):\n",
    "    for j in range(150):\n",
    "        testim[i,j]=(((i-25)*150)+(j-25))/10000\n",
    "plt.imshow(testim,cmap=test_map(reverse=True))\n",
    "plt.imshow(testim,cmap=blues_map(reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testim=np.zeros((150,150))\n",
    "for i in range(150):\n",
    "    for j in range(150):\n",
    "        testim[i,j]=(((i-25)*150)+(j-25))/10000\n",
    "plt.imshow(testim,cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import io as sio\n",
    "sio.savemat(\"densities_matrix\",{\"dens\":densities_matrix})\n",
    "sio.savemat(\"q_matrix\",{\"q_matrix\":q_matrix})\n",
    "sio.savemat(\"risk_matrix\",{\"risk_matrix\":risk_matrix})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sio.savemat(\"G_size\",{\"G\":np.array(G_size)})\n",
    "sio.savemat(\"SG_size\",{\"SG\":np.array(SG_size)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sio.savemat(\"q_for_G_SG\",{\"q\":q})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.savemat(\"frac_acc_hosp\",{\"frac\":frac_access_hosp})\n",
    "sio.savemat(\"frac_acc_fire\",{\"frac\":frac_access_fire})\n",
    "\n",
    "sio.savemat(\"frac_acc_ts\",{\"frac\":frac_access_ts})\n",
    "sio.savemat(\"frac_acc_coffee\",{\"frac\":frac_access_coffee})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(frac_access_hosp.shape)\n",
    "print(q[::6].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "l1,=plt.plot(1000*densities,q[::6],label=r\"$q$\",c=custom_cm(0))\n",
    "l2,=plt.plot(np.arange(80),np.ones(80)*.45,'--',label=r\"$q^*$\",c=custom_cm(1))\n",
    "plt.grid(lw=.5)\n",
    "plt.xlim(0,80)\n",
    "plt.ylim(0,1.05)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"number hacked cars per km per lane\",fontsize=18)\n",
    "plt.ylabel(r\"$q$\",fontsize=18)\n",
    "plt.legend(fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ltot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.savemat(\"q for dens\",{\"q\":q})\n",
    "sio.savemat(\"number hacked pkmpl\",{\"num\":1000*densities})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(densities_matrix-.001<.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "densities_matrix[390,79]\n",
    "q_matrix[390,79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "midc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "midc/1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import io as sio\n",
    "q_matrix=sio.loadmat('q_matrix.mat')\n",
    "q_matrix=q_matrix['q_matrix']\n",
    "q=sio.loadmat(\"q for dens.mat\")['q']\n",
    "densities=sio.loadmat(\"number hacked pkmpl.mat\")['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frac_access_hosp=sio.loadmat(\"frac_acc_hosp.mat\")['frac']\n",
    "frac_access_fire=sio.loadmat(\"frac_acc_fire.mat\")['frac']\n",
    "frac_access_ts=sio.loadmat(\"frac_acc_ts.mat\")['frac']\n",
    "frac_access_coffee=sio.loadmat(\"frac_acc_coffee.mat\")['frac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.savemat(\"frac_acc_well_dist\",{\"frac\":frac_access_well_dist})\n",
    "sio.savemat(\"frac_acc_med_dist\",{\"frac\":frac_access_med_dist})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trials=2\n",
    "num_densities=40\n",
    "densities=np.linspace(0,.08,num_densities)\n",
    "frac_access_em_dist=np.zeros((num_densities,num_trials))\n",
    "\n",
    "print(\"starting trials...\")\n",
    "\n",
    "for this_density in range(num_densities):\n",
    "    rho=densities[this_density]\n",
    "    road_probs=[]\n",
    "    print(\"Getting road probabilities, %s ...\"%(str(round(rho,3))))\n",
    "    for i in range(9665):\n",
    "        road_probs.append(pperc(float(Ls[i]),14,float(ls[i]),rho))\n",
    "    #q[this_density]=np.average(road_probs)\n",
    "    for this_trial in range(num_trials):\n",
    "        #print(\"running density: %s, trial %d\"%(str(round(rho,3)),this_trial))\n",
    "        drops=[]\n",
    "        for p in road_probs:\n",
    "            if np.random.random()<np.real(p):\n",
    "                drops.append(True)\n",
    "            else:\n",
    "                drops.append(False)\n",
    "\n",
    "        elist=[edge for edge in G.edges]\n",
    "        droplist=[elist[i] for i in np.where(drops)[0]]\n",
    "        uGp=G.copy()\n",
    "        uGp.remove_edges_from(droplist)\n",
    "        uGp=nx.to_undirected(uGp)\n",
    "        \n",
    "        ctr=0\n",
    "        num_police_in_graph=[]\n",
    "        for ob in nx.connected_component_subgraphs(uGp):\n",
    "            ctr=0\n",
    "            for node in em_dist_nodes:\n",
    "                if node in ob.nodes:\n",
    "                    ctr+=1\n",
    "            num_police_in_graph.append((len(ob.nodes),ctr))\n",
    "        safe_nodes=0; risk_nodes=0;\n",
    "        for tup in num_police_in_graph:\n",
    "            if tup[1]==0:\n",
    "                risk_nodes+=tup[0]\n",
    "            else:\n",
    "                safe_nodes+=tup[0]\n",
    "        print(\"fraction of nodes w access to Times Square: \"+str(round(safe_nodes/(safe_nodes+risk_nodes),3)))\n",
    "        print(\"trial num: \"+str(this_trial))\n",
    "        frac_access_em_dist[this_density,this_trial]=safe_nodes/(safe_nodes+risk_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em_dist_nodes=[n for n in G.nodes if np.random.random()<.0038]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_densities=50\n",
    "densities=np.linspace(0,.08,num_densities)\n",
    "#ax1=plt.plot()\n",
    "plt.figure(figsize=(9,4.5))\n",
    "plt.semilogy()\n",
    "#plt.errorbar(q,y=np.average(G_size,axis=1),yerr=np.std(G_size,axis=1),color='g',alpha=.5)\n",
    "plt.errorbar(1000*densities,y=np.average(frac_access_hosp,axis=1),yerr=np.std(frac_access_hosp,axis=1),color='white',marker='^',lw=1.8,mec='r',ms=8,alpha=.6,ecolor='pink')\n",
    "plt.errorbar(1000*densities,y=np.average(frac_access_fire,axis=1),yerr=np.std(frac_access_fire,axis=1),color='red',marker='o',lw=1.8,mec='k',ms=8,alpha=.6)\n",
    "plt.errorbar(1000*densities,y=np.average(frac_access_ts,axis=1),yerr=np.std(frac_access_ts,axis=1)/1.5,color='gray',marker='s',lw=1.8,mec='k',ms=8,alpha=.6)\n",
    "#plt.errorbar(1000*densities,y=np.average(frac_access_coffee,axis=1),yerr=np.std(frac_access_coffee,axis=1),color='saddlebrown',marker='o',lw=1.8,mec='k',ms=8,alpha=1)\n",
    "plt.errorbar(1000*densities,y=np.average(frac_access_well_dist,axis=1),yerr=np.std(frac_access_well_dist,axis=1),color='purple',marker='o',lw=1.8,mec='k',ms=8,alpha=1)\n",
    "#plt.errorbar(1000*densities,y=np.average(frac_access_med_dist,axis=1),yerr=np.std(frac_access_med_dist,axis=1),color='blue',marker='s',lw=1.8,mec='k',ms=8,alpha=.5)\n",
    "plt.errorbar(1000*np.linspace(0,.08,40),y=np.average(frac_access_em_dist,axis=1),yerr=np.std(frac_access_em_dist,axis=1),color='green',marker='s',lw=1.8,mec='k',ms=8,alpha=.5)\n",
    "#plt.semilogy(1000*densities,frac_access_police,color='cadetblue',marker='o',lw=1.8,mec='k',ms=8,alpha=.6)\n",
    "#plt.semilogy(1000*densities,frac_access_coffee,color='peru',marker='o',lw=1.8,mec='k',ms=8,alpha=.6)\n",
    "#plt.semilogy(1000*densities,frac_access_hindu,color='purple',marker='o',lw=1.8,mec='k',ms=8,alpha=.6)\n",
    "#ax2=ax1.twinx()\n",
    "#plt.plot(q,np.average(SG_size,axis=1),c='coral',marker='o',alpha=.5,mec='k',ms=8)\n",
    "#plt.errorbar(q,y=np.average(SG_size,axis=1),yerr=2*np.std(SG_size,axis=1),color='coral',alpha=.5)\n",
    "#plt.xticks([.1*i for i in range(11)])\n",
    "plt.xticks(fontsize=16)\n",
    "plt.ylim(1e-3,1e0)\n",
    "#locs,_=plt.yticks()\n",
    "locs=np.array([1e-4,1e-3,1e-2,1e-1,1e0])\n",
    "labels=[\"100%\",\"10%\",\"1%\",\"0.1%\",\"0.01%\"]\n",
    "labels=reversed(labels)\n",
    "plt.yticks(locs,labels,fontsize=16)\n",
    "plt.ylabel(\"Percent of nodes with access\",fontsize=18)\n",
    "plt.xlabel(r\"$\\rho_H$\",fontsize=18)\n",
    "plt.xlim(0,60)\n",
    "#plt.grid('gray',lw=.4)\n",
    "plt.legend([\"hospital\",\"fire station\",\"Times Square\",\"random 10%\",\"random 0.5%\"],fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Timestamps\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# City network and plots\n",
    "import osmnx as ox, geopandas as gdp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To replace output plots for streaming\n",
    "from IPython import display\n",
    "\n",
    "# Sets intervals for updating the plot\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where the web scraper script is outputting files\n",
    "streamFilePath = \"/Users/dyanni3/Documents/GitHub/Blog/traffic_stream_data/\"\n",
    "\n",
    "# Number of seconds for Spark to ingest the data files\n",
    "microBatchSeconds = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieving the network for Manhattan\n",
    "manhattan = ox.graph_from_place('Manhattan, New York, USA', network_type='drive')\n",
    "\n",
    "# Projecting the network for a top-down view\n",
    "manhattan_projected = ox.project_graph(manhattan)\n",
    "\n",
    "# Importing only the fields we're interested in\n",
    "dfNodes = pd.read_csv('/Users/dyanni3/Documents/GitHub/Blog/traffic_stream_data/nycTraffic_20180910-132111.txt',\n",
    "            usecols=[0, 6, 11],\n",
    "            names=['id', 'linkPoints', 'borough'])\n",
    "\n",
    "# Filtering to Manhattan and dropping the borough column\n",
    "dfNodes = dfNodes[dfNodes['borough'] == 'Manhattan']\n",
    "dfNodes = dfNodes[['id', 'linkPoints']]\n",
    "\n",
    "# Splitting the column containing all Lat/Long combinations\n",
    "dfNodes['splitPoints'] = dfNodes['linkPoints'].apply(lambda x: x.split(' '))\n",
    "\n",
    "# Reshaping our data frame to have a row for each Lat/Long point\n",
    "idNodes = []\n",
    "for x,y in zip(dfNodes['splitPoints'], dfNodes['id']):\n",
    "    for a in np.arange(len(x)):\n",
    "        idNodes.append((y, x[a]))\n",
    "dfNodes = pd.DataFrame(idNodes, columns=['id', 'LatLong'])\n",
    "\n",
    "dfNodes = dfNodes.replace('', np.NaN).dropna()\n",
    "\n",
    "# Parsing Lat/Long into individual columns\n",
    "# Longitude has an if statement since some records contain '-' for longitude\n",
    "dfNodes['Latitude'] = dfNodes['LatLong'].apply(lambda x: x.split(';')[0])\n",
    "dfNodes['Longitude'] = dfNodes['LatLong'] \\\n",
    "    .apply(lambda x: x.split(';')[1] if len(x.split(';')) > 1 else None)\n",
    "\n",
    "# Dropping incorrect longitude records and converting everything to floats\n",
    "dfNodes = dfNodes[dfNodes['Longitude'] != '-'][['id', 'Latitude', 'Longitude']].astype(float)\n",
    "dfNodes.dropna();\n",
    "\n",
    "# Obtaining the nearest nodes in the network from the Lat/Long points\n",
    "nodes = []\n",
    "for row in dfNodes.iterrows():\n",
    "    try:\n",
    "        nearest_node = ox.get_nearest_node(manhattan, (dfNodes['Latitude'].ix[row], \n",
    "                                                   dfNodes['Longitude'].ix[row]))\n",
    "        nodes.append(nearest_node)\n",
    "    except ValueError:\n",
    "        nodes.append(np.NaN)\n",
    "    \n",
    "\n",
    "dfNodes['node'] = nodes\n",
    "\n",
    "# Removing duplicate nodes\n",
    "dfNodes.drop_duplicates(subset='Node', inplace=True)\n",
    "dfNodes.dropna(inplace=True)\n",
    "\n",
    "dfNodes['linkPoints ID']=dfNodes['id']\n",
    "dfNodes.drop('id',axis=1)\n",
    "\n",
    "dfNodes.to_csv('linkPoints_to_latLong.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_traffic_data = '/Users/dyanni3/Documents/GitHub/Blog/traffic_stream_data/'\n",
    "glob_string = path_to_traffic_data+'*.txt'\n",
    "import glob\n",
    "files = glob.glob('/Users/dyanni3/Documents/GitHub/Blog/traffic_stream_data/*.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names = ['linkpoints','speed','lp2','linkID','lat-long-pairs','borough']\n",
    "df = pd.concat([pd.read_csv(f,usecols=[0,1,2,5,6,11],names=col_names,header=None) for f in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat = []; long=[];\n",
    "for i,row in enumerate(df.iterrows()):\n",
    "        ll=(np.array(row[1]['lat-long-pairs'].split(' ')[0].split(';'),dtype='float'))\n",
    "        lat.append(ll[0])\n",
    "        long.append(ll[1])\n",
    "df['lat']=pd.Series(lat)\n",
    "df['long']=pd.Series(long)\n",
    "df=df[df['borough']=='Manhattan'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for row in df.iterrows():\n",
    "    try:\n",
    "        nearest_node = ox.get_nearest_node(manhattan, (df['lat'].iloc[row[0]], \n",
    "                                                   df['long'].iloc[row[0]]))\n",
    "        nodes.append(nearest_node)\n",
    "    except ValueError:\n",
    "        nodes.append(np.NaN)\n",
    "df['node'] = nodes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.hist('speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nov_data_path='/Users/dyanni3/Downloads/november2016.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "novData=pd.read_csv(nov_data_path)\n",
    "novData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date=[]\n",
    "time=[]\n",
    "for splitted in (novData['DataAsOf']).apply(lambda x: x.split(' ')):\n",
    "    date.append(splitted[0])\n",
    "    time.append(splitted[1])\n",
    "\n",
    "novData['date']=pd.Series(date)\n",
    "novData['time']=pd.Series(time)\n",
    "novData.drop('DataAsOf',axis=1,inplace=True);\n",
    "novData['Speed']=pd.to_numeric(novData.Speed);\n",
    "novData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "novData[novData['date']=='11/3/2016'].hist('Speed')\n",
    "novData[novData['date']=='11/18/2016'].hist('Speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "novData=novData[novData['Speed']<100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "macy_lat=40.45040; macy_long=73.59221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ox.get_nearest_node(manhattan,(macy_lat,macy_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def euclidean(l1,l2):\n",
    "    r2=(l1-macy_lat)**2 + (l2-macy_long)**2\n",
    "    return(r2**.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx=np.argmin(euclidean(df.lat,df.long))\n",
    "d=np.min(euclidean(df.lat,df.long))\n",
    "print(\"idx==%d  d==%s\"%(idx,str(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nearParadeIDs = df[euclidean(df.lat,df.long)<148.525].linkID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "novData.linkId==df.iloc[np.argmin(euclidean(df.lat,df.long))].linkID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearParade=novData[novData.linkId==df.iloc[np.argmin(euclidean(df.lat,df.long))].linkID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nearParade.hist('Speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thxDay=nearParade[nearParade['date']=='11/24/2016']\n",
    "thxDayNoon=[]\n",
    "for i in range(50):\n",
    "    thxDayNoon.append(thxDay.iloc[144+i])\n",
    "thxDayNoon=pd.DataFrame(thxDayNoon)\n",
    "thxDayNoon.hist(\"Speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = [\"11/%d/2016\"%(i) for i in range(1,31)]\n",
    "mean_speeds=[]\n",
    "std_speeds=[]\n",
    "time_range=[]\n",
    "for date in dates:\n",
    "    thisDay=nearParade[nearParade['date']==date]\n",
    "    thisDayNoon=[]\n",
    "    for i in range(thisDay.shape[0]):\n",
    "        if (pd.to_datetime(thisDay.iloc[i].date+\" \"+thisDay.iloc[i].time) > pd.to_datetime(thisDay.iloc[i].date+\" \"+\"12:00:00\"))\\\n",
    "        and (pd.to_datetime(thisDay.iloc[i].date+\" \"+thisDay.iloc[i].time) < pd.to_datetime(thisDay.iloc[i].date+\" \"+\"20:00:00\")):\n",
    "            thisDayNoon.append(thisDay.iloc[i])\n",
    "    thisDayNoon=pd.DataFrame(thisDayNoon)\n",
    "    try:\n",
    "        mean_speeds.append(np.average(thisDayNoon.Speed))\n",
    "        std_speeds.append(np.std(thisDayNoon.Speed))\n",
    "    except AttributeError:\n",
    "        mean_speeds.append(13)\n",
    "        std_speeds.append(0)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pd.to_datetime(thisDay.iloc[0].date+\" \"+thisDay.iloc[0].time))\n",
    "print(pd.to_datetime(thisDay.iloc[1].date+\" \"+\"12:00:00\"))\n",
    "pd.to_datetime(thisDay.iloc[0].date+\" \"+\"12:00:00\") < pd.to_datetime(thisDay.iloc[1].date+\" \"+thisDay.iloc[1].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print([round(num,3) for num in mean_speeds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.sort(mean_speeds),'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spds =(list(zip(pd.to_datetime(dates),np.array(mean_speeds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spds=pd.DataFrame(spds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.errorbar(np.arange(30),spds[1],yerr=std_speeds,marker='o',markersize=8,lw=0,elinewidth=.05,capsize=2,alpha=.75)\n",
    "plt.scatter(23,spds[1][23],color='r',s=70)\n",
    "y_av=np.ones(30)*np.average(spds[1])\n",
    "plt.plot(np.arange(30),y_av,'r--')\n",
    "error = 1.4*np.ones(30)*np.std(spds[1])\n",
    "plt.fill_between(np.arange(30),y_av-error,y_av+error,alpha=.3)\n",
    "plt.fill_between(np.arange(30),y_av-2*error,y_av+2*error,color='g',alpha=.1)\n",
    "plt.grid(lw=.5)\n",
    "plt.xticks(np.arange(30),dates,rotation='vertical');\n",
    "plt.ylabel(\"Average Speed\",fontsize=16)\n",
    "plt.xlabel(\"Date\",fontsize=16)\n",
    "plt.ylim(20,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "novData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spds[1][23]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ell = list(df.linkID)\n",
    "uniq_nov_linkIds = pd.unique(novData.linkId)\n",
    "sharedIDs = [uniq_nov_linkIds[i] for i in range(uniq_nov_linkIds.size) if uniq_nov_linkIds[i] in ell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals = [[pd.unique(df.lat[df.linkID == sharedIDs[i]])[0],\\\n",
    "                      pd.unique(df.long[df.linkID == sharedIDs[i]])[0],\\\n",
    "                      pd.unique(df.linkID[df.linkID == sharedIDs[i]])[0]] for i in range(len(sharedIDs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sharedMapDF = pd.DataFrame(vals,columns=['lat','long','linkId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sharedMapDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N=100 #Nodes per side\n",
    "square_grid=nx.grid_2d_graph(N,N)\n",
    "labels = dict( ((i,j), i + (N-1-j) * N ) for i, j in square_grid.nodes() )\n",
    "nx.relabel_nodes(square_grid,labels,False)\n",
    "inds=labels.keys()\n",
    "vals=labels.values()\n",
    "inds=sorted(inds,reverse=False)\n",
    "vals=sorted(vals, reverse=False)\n",
    "pos2=dict(zip(vals,inds))\n",
    "nx.draw_networkx(square_grid, pos=pos2, with_labels=False, node_size = 4, node_color='red')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pp(rho):\n",
    "    phi = .07; L=.2;\n",
    "    inner = (phi**2)*(2-phi)**2\n",
    "    inner=1-inner\n",
    "    inner=inner**((L*2*rho)**2)\n",
    "    return 1-inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rho = np.linspace(0,80,200)\n",
    "plt.plot(rho,Pp(rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(square_grid.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trials=100\n",
    "num_densities=30\n",
    "densities=np.linspace(0,30,num_densities)\n",
    "num_components_fine=np.zeros((num_densities,num_trials))\n",
    "G_size=np.zeros((num_densities,num_trials))\n",
    "SG_size=np.zeros((num_densities,num_trials))\n",
    "q=np.zeros(num_densities)\n",
    "\n",
    "print(\"starting trials...\")\n",
    "\n",
    "for this_density in range(num_densities):\n",
    "    rho=densities[this_density]\n",
    "    road_probs=[]\n",
    "    q[this_density]=Pp(rho)\n",
    "    for this_trial in range(num_trials):\n",
    "        #print(\"running density: %s, trial %d\"%(str(round(rho,3)),this_trial))\n",
    "        drops=[]\n",
    "        for i in range(len(square_grid.edges)):\n",
    "            if np.random.random()<q[this_density]:\n",
    "                drops.append(True)\n",
    "            else:\n",
    "                drops.append(False)\n",
    "\n",
    "        elist=[edge for edge in square_grid.edges]\n",
    "        droplist=[elist[i] for i in np.where(drops)[0]]\n",
    "        uGp=square_grid.copy()\n",
    "        uGp.remove_edges_from(droplist)\n",
    "        uGp=nx.to_undirected(uGp)\n",
    "        \n",
    "        num_components_fine[this_density,this_trial]=nx.number_connected_components(uGp)\n",
    "        this_list=[nx.number_of_edges(ob) for ob in nx.connected_component_subgraphs(uGp)]\n",
    "        G_size[this_density,this_trial]=max(this_list)\n",
    "        if len(this_list)>1:\n",
    "            this_list.remove(max(this_list))\n",
    "            SG_size[this_density,this_trial]=max(this_list)\n",
    "        else:\n",
    "            SG_size[this_density,this_trial]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.errorbar(densities,y=np.average(G_size,axis=1),\\\n",
    "             yerr=np.std(G_size,axis=1),\\\n",
    "             color=np.array([120,120,255])/255,alpha=1,\\\n",
    "             elinewidth=2,capsize=3,lw=.7)\n",
    "plt.plot(densities,np.average(G_size,axis=1),\\\n",
    "         color=np.array([120,120,255])/255,marker='o',\\\n",
    "         lw=0,mec=np.array([120,120,255])/255,ms=6,alpha=.5)\n",
    "plt.plot(densities,np.average(SG_size,axis=1),c='k',\\\n",
    "         marker='v',alpha=.3,mec='k',ms=4,lw=0)\n",
    "plt.errorbar(densities,y=np.average(SG_size,axis=1),\\\n",
    "             yerr=np.std(SG_size,axis=1),color='blue',alpha=.7,\\\n",
    "            lw=.3,capsize=0,elinewidth=2)\n",
    "#plt.xticks([10*i for i in range(9)])\n",
    "#plt.yticks([1000*i for i in range(9)])\n",
    "plt.ylabel(\"cluster size\",fontsize=18)\n",
    "plt.xlabel(r\"$\\rho_H$\",fontsize=18)\n",
    "plt.grid('gray',lw=.1)\n",
    "plt.xlim(0,30)\n",
    "#plt.yticks([2000*i for i in range(5)],fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.legend([\"Largest Component\",\"Second Largest Component\"],fontsize=14)\n",
    "plt.title(\"100 by 100 grid\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(uGp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = [\"11/%d/2016\"%(i) for i in range(1,31)]\n",
    "mean_speeds=[]\n",
    "std_speeds=[]\n",
    "time_range=[]\n",
    "for date in dates:\n",
    "    print(date)\n",
    "    thisDay=novData[novData['date']==date]\n",
    "    thisDayNoon=[]\n",
    "    print(thisDay.shape)\n",
    "    for i in range(thisDay.shape[0]):\n",
    "        if(i%10000==0):\n",
    "            print(i)\n",
    "        if (pd.to_datetime(thisDay.iloc[i].date+\" \"+thisDay.iloc[i].time) > pd.to_datetime(thisDay.iloc[i].date+\" \"+\"12:00:00\"))\\\n",
    "        and (pd.to_datetime(thisDay.iloc[i].date+\" \"+thisDay.iloc[i].time) < pd.to_datetime(thisDay.iloc[i].date+\" \"+\"20:00:00\")):\n",
    "            thisDayNoon.append(thisDay.iloc[i])\n",
    "    thisDayNoon=pd.DataFrame(thisDayNoon)\n",
    "    try:\n",
    "        mean_speeds.append(np.average(thisDayNoon.Speed))\n",
    "        std_speeds.append(np.std(thisDayNoon.Speed))\n",
    "    except AttributeError:\n",
    "        mean_speeds.append(13)\n",
    "        std_speeds.append(0)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_speeds[1]=np.average(mean_speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:OSMNX]",
   "language": "python",
   "name": "conda-env-OSMNX-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
